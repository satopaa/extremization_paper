\let\mymarginpar\marginpar

\documentclass[11pt,twoside]{article}

%\long\def\authornote#1{%
%        \leavevmode\unskip\raisebox{-3.5pt}{\rlap{$\scriptstyle\diamond$}}%
%        \marginpar{\raggedright\hbadness=10000
%        \def\baselinestretch{0.8}\tiny
%        \it #1\par}}
%\newcommand{\ville}[1]{\authornote{NOTE TO SELF: #1}}

\marginparwidth=1cm
\marginparsep=5pt
\newcommand\ville[1]{%
    \mymarginpar{\raggedright\hbadness=10000\tiny\it #1\par}}


\usepackage{amsmath} 
\usepackage{times}
\usepackage{amsmath,amsthm,amssymb}
\usepackage{fancyhdr}
\usepackage{moreverb}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{url}
\usepackage{multirow} 
\usepackage[boxed, section]{algorithm}
%\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{cite}
\usepackage{multirow} 
\usepackage{rotating}
\usepackage{geometry}
\usepackage{fix-cm}
%\usepackage{subfigure}
\usepackage{natbib}
\usepackage{caption}
\usepackage{subcaption}

\renewcommand{\baselinestretch}{1.2}
\setlength{\topmargin}{-0.3in}
\setlength{\textwidth}{6in}
\setlength{\textheight}{8.5in}
\setlength{\oddsidemargin}{0.25in}
\setlength{\evensidemargin}{0.25in}
\raggedbottom




\allowdisplaybreaks

% Math Macros.  It would be better to use the AMS LaTeX package,
% including the Bbb fonts, but I'm showing how to get by with the most
% primitive version of LaTeX.  I follow the naming convention to begin
% user-defined macro and variable names with the prefix "my" to make it
% easier to distiguish user-defined macros from LaTeX commands.
%
\newcommand{\myN}{\hbox{N\hspace*{-.9em}I\hspace*{.4em}}}
\newcommand{\myZ}{\hbox{Z}^+}
\newcommand{\myR}{\hbox{R}}
\renewcommand{\P}{\mathbb{P}}
\newcommand{\E}{\mathbb{E}}
\newtheorem{defi}{Definition}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Observation}
\newtheorem{observation}[theorem]{Observation}


\newcommand{\myfunction}[3]
{${#1} : {#2} \rightarrow {#3}$ }

\newcommand{\myzrfunction}[1]
{\myfunction{#1}{{\myZ}}{{\myR}}}


\newcommand{\mysection}[1]
{\noindent {\bf {#1}}}

%%%%%% Begin document with header and title %%%%%%%%%

\begin{document}

\title{Information Theoretic Model for Subjective Response Data with an Application to Probability Extremization}
%\title{A Novel Framework for Analyzing Subjective Response Data}
\author{
Ville A. Satop\"a\"a, Robin Pemantle, and Lyle H. Ungar\\
\\
 \small Department of Statistics\\
 \small The Wharton School of the University of Pennsylvania\\
 \small Philadelphia, PA 19104- 6340, USA\\ [-0.25in]} \date{}
\maketitle

\pagestyle{myheadings}
\markboth{Information Theoretic Signal Generation}{Satop\"a\"a et al.}
\thispagestyle{empty}

\begin{abstract}
Typically randomness in scientific estimation is assumed to arise from unmeasured or uncontrolled factors. Recent developments, however, show that heterogeneity stemming from cognitive diversity is more appropriate for subjective response data. This paper presents an information theoretic framework that is mathematically convenient, generates estimate heterogeneity from cognitive diversity, and is particularly appropriate for subjective response data. This framework is illustrated on probability aggregation. The probabilities are given by a group of experts who forecast whether an event will occur or not. Our aggregator uses the distribution of information among the experts and depends on easily interpretable parameters. Even though shifting the average probability forecasts closer to its nearest extreme, known as \textit{extremizing}, has been acknowledged to yield improved forecast performance, it is much less understood when and how much the average forecast should be extremized. By assuming a simplified information structure in our model, the amount of extremizing is studied closely under different groups of experts. This leads to novel observations and a more principled understanding of extremization.
\end{abstract}

%data generative process. 


\section{Introduction}
Consulting experts are often asked to make estimates under incomplete information. If the experts form their estimates independently of each other, their estimates are likely to be different. To analyze the estimates with  statistical methodology, it is mathematically convenient and often necessary to assume that these differences  arise from a probability distribution. For instance, consider a group of experts who aim to eyeball the height of a building. Their estimates can be modeled as independent draws from a Gaussian distribution that is centered at the true height. Even though distributional assumptions clearly oversimplify the reality, they are typically useful enough to improve our understanding of the world. 

Unfortunately, this is unlikely to be the case with subjective response data such as experts' beliefs. \cite{hong2009interpreted} explain how standard distributional assumptions can be dramatically misaligned  with the process that generates subjective responses. As an alternative to the aforementioned process of  \textit{generating} estimates from a probability distribution, they introduce the idea of  \textit{interpreted} estimates. An estimate is said to be interpreted if the expert first filters reality into set of categories and then makes an estimate by applying active cognitive effort to these categories. For instance, consider an Olympic judge who is evaluating a figure skating performance. The judge first interprets the performance with the aid of categories, and then scrutinizes that experience into a final score. Therefore any differences between estimates is assumed to arise from cognitive diversity instead of an underlying probability distribution.

%The observation that people use categories to interpret the world is well-established in the psychology literature (see, e.g, \citet{fryer2008categorical, page2008difference}).  

The interpretive framework is clearly a more realistic model for subjective response data. Given that this kind of data is very common in real-world applications, such as product reviews, online auctions, and voting, this framework shows great potential in improving our understanding of many experimental results. Unfortunately, the interpretive framework is more of an abstract concept than a concrete model for subjective response data. Therefore it is not clear how this framework can be applied in complex real world situations. 
%The framework does, however, offer  some novel and useful directions.


The first contribution of this paper is to introduce a concrete model that can be used to analyze subjective response data in a real-world situation. 
%This model shares several key characteristics with the interpretive framework and therefore ends up supporting many of the observations made in \cite{hong2009interpreted}. 
The model is considered \textit{information theoretic} as it is based on the distribution of information among the experts. The information structure is completely characterized by the amount of information known by each expert and the amount information shared between any two experts. For instance, experts $A$ and $B$ may know 10\% and 5\%  of the full information, respectively. If they share 2.5\% of the full information, then their information sets overlap and their estimates are assumed to be positively correlated. The experts are assumed to give optimal estimates conditional on their private information sets. This means that a larger information set typically leads to a more accurate estimate, and two identical information sets lead to the same estimate. Similarly to the interpretative framework, any heterogeneity in the estimates arises from cognitive diversity. In reality experts, however, do not typically make optimal use of their information. Therefore the information theoretic framework is a simplification of the psychological nature of the process that generates subjective responses. It does, however, offer a compromise that strikes a good balance between psychological realism and analytical convenience. Therefore it is a platform that is particularly convenient for development of future methodology.

The second contribution of this paper is to apply the information theoretic framework  on probability aggregation. Combining multiple probability forecasts is an important problem with many applications including medical diagnosis (\citet{wilson1998prediction, pepe2003statistical}), political and socio-economic foresight (\citet{tetlock2005expert}), and meteorology (\citet{sanders1963subjective, vislocky1995improved, baars2005performance}). There is strong empirical evidence that bringing together the strengths of different experts by combining their probability forecasts into a single consensus, known as the \textit{crowd belief},  improves predictive performance. For instance, consider the aforementioned experts $A$ and $B$. The union of their information sets covers 12.5\% of the full information. Therefore it seems plausible that some combination of their probability forecasts is more informed than either one of the individual probabilities. The naive approach is to simply average the individual probability forecasts. To see why this approach can be problematic, recall that $A$'s forecast is based on a larger information set and hence typically more accurate than $B$'s forecast. Therefore $A$'s forecast is on average closer to the actual outcome of the event ($0$ if it does not happen and $1$ if it does happen) and should be given a higher weight in the final aggregate.  The average of the forecast, however, gives each forecast equal weight in the final aggregate and hence ends up being necessarily too close to 0.5. Recent developments suggest that shifting the average probability closer to its nearest extreme (0.0 or 1.0), known as \textit{extremizing}, yields improved forecasting performance. For instance, \citet{satopaa} uses a linear regression model in the logit-space to derive an extremizing aggregator that performs well on real-world data. \citet{Ranjan08} propose transforming the average probability with the cumulative distribution function of a beta distribution. If both the shape and scale of this beta distribution are equal and constrained to be at least 1.0,  the aggregator extremizes and has some attractive theoretical properties (\cite{Wallsten2001}).  \citet{Baron} provide yet another extremizing aggregation in addition to two intuitive justifications for extremizing.

%To give an intuitive justification for extremization,  consider a binary event whose outcome is still uncertain.  For the sake of illustration, assume that 0.9 is the most informed probability forecast that could be given based on all the available information. Before having any knowledge of the event, a rational forecaster aiming to minimize a reasonable loss function, such as the Brier score, has no reason to give anything but 0.5 as his probability forecast. In the Bayesian terminology, this estimate can be viewed as his prior belief. As he acquires more information, he updates his prior belief accordingly.  This updated belief, which can be viewed as his posterior belief, is a compromise between his prior belief and the information acquired. Because he does not have all the available information, his estimate is conservative and necessarily too close to 0.5. If most forecasters fall somewhere on this spectrum between ignorance and full information, their average forecast tends to fall strictly between 0.5 and 0.9. It this difference between the ``true probability" and the average forecast that extremization aims to close. 

These aggregators, however, are based on ad hoc techniques that learn the amount of extremization by optimizing a scoring rule over a separate training set (\citet{Gneiting04strictlyproper}). It is concerning that extremization does not arise naturally from the underlying model. These aggregators are also too detached from the psychology literature to provide any insight beyond the aggregate probability. Therefore it is still not well-understood when and how much the average probability should be extremized. 
%Therefore it is necessary to learn the amount of extremizing from a separate training dataset. Furthermore, many of these aggregators assume that the individual probability forecasts arise from the generative framework. Under this assumption the optimal aggregation is accessible by weighted averaging (\cite{parunak2013characterizing}). However, given that extremizing is known to improve the performance of the aggregate, it is unlikely that the generative framework is appropriate for probability aggregation. 
This paper remedies these shortcomings by developing an aggregator that is based on the information theoretic framework. Under this model the average forecast is always extremized. The amount of extremization is given in a closed-form expression that can be applied to any number of experts with any given information structure. By assuming a simplified information structure, the amount of extremization can be made to depend only on three intuitive parameters. This allows us to visualize extremization and make concrete statements on when and how much extremization should be performed. 

This paper is structured as follows. The first section introduces our information theoretic framework and  compares it with the generative and interpretive frameworks. The second section applies the framework to probability forecasts. The third section derives a closed-form expression for the amount of extremization and analyzes this expression under unstructured and a compound symmetric information structure. The paper concludes with a discussion of  model limitations and future directions. 



\section{Information Theoretic Framework}
This section discusses the information theoretic framework in comparison with the generative and interpretive frameworks. This comparison is by no means comprehensive as signal generation is a large part of the statistical literature. The first subsection builds  intuition via a simple example. The second subsection provides a technical comparison. 

\subsection{Simple Example}
Consider two experts $1$ and $2$ who are observing a hockey tournament. The tournament consists of three games played between teams RED and BLUE. After seeing the outcome of the first game, the experts are asked to report the probability of RED winning the tournament. Assume that RED wins if $G_1 + G_2 + G_3 \geq 0$, where $G_k \in \{-1,1\}$ indicates whether RED won the $k$th game. Suppose that all 8 possible combinations are equally likely. 
%Therefore the true probability of team RED winning the tournament is 1/2.

\begin{enumerate}
\item[] \textit{Generated Estimate:} Based on the first game, the $i$th expert believes that RED has an independent chance of $q_i$ winning any of the two remaining games. This likelihood is assumed to arise from a probability distribution defined on the unit interval. Therefore any individual differences in the way the experts process the first game and turn the acquired information into probabilities $q_1$ and $q_2$ are assumed to arise from a probability distribution. The exports report
\begin{align}
p_i &= \begin{cases}
q_i(2-q_i) & \text{ if } G_1 = 1\\
q_i^2 & \text{ if } G_1 = -1
\end{cases}
\label{basisP}
\end{align}

\item[] \textit{Interpreted Estimate:} Interpretations are different ways of seeing the first game. Assume that RED's performance can be attributed entirely to its \textit{defense} $D$ and \textit{offense} $O$ that are equally likely to be either good 1 or bad -1. Expert 1 follows only the defense and Expert 2 looks only at the offensive play. Based on these attributes the experts construct their final predictive models. Under the generative framework the details of these predictive models were abstracted into a probability distribution. Under the interpretive framework, however, the details are fixed and known. For instance, the experts may report (\ref{basisP}) with
%If RED wins a game when $D + 2O \geq 2$, the experts report (\ref{basisP}) but with
\begin{align*}
q_1 = \begin{cases}
2/3 & \text{ if } D = 1\\
1/3 &  \text{ if } D = -1
\end{cases}
&& q_2 &= \begin{cases}
3/5 & \text{ if } O = 1\\
2/5 & \text{ if } O = -1
\end{cases}
\end{align*}
Each expert interprets the available information independently and subjectively.  Therefore even if the experts observed the same attributes of the game, their probability forecasts do not need to be the same. 


\item[] \textit{Information Theoretic Estimate:} The experts know that RED has a 1/2 chance of winning any given game. Suppose that expert 1 knows the number of wins in the first two games, i.e. the value of $G_1 + G_2$, but not necessarily the separate outcomes of the two games. Assume that expert 2 only knows the outcome of the first game $G_1$. Then,
\begin{align*}
p_1 = \begin{cases}
0 & \text{ if } G_1 + G_2 = -2\\
1/2 & \text{ if } G_1 + G_2 = 0\\
1 & \text{ if } G_1 + G_2 = 2\\
\end{cases}
&& p_2 = \begin{cases}
1/4 & \text{ if } G_1 = -1\\
3/4 & \text{ if } G_1 = 1\\
\end{cases}
\end{align*}
Experts 1 and 2 know 2/3 and 1/3 of the full information, respectively. Their predictive models are completely determined by the size of their private information sets. As their information sets overlap by 1/3 of the full information, their probability forecasts are positively correlated. In this example, the correlation coefficient for their forecasts is $\sqrt{2}/2$.  


\end{enumerate}


\subsection{Technical Details}
Let  $(\Omega, \mathcal{F}, \P)$ be a probability space, where the set $\Omega$ contains all possible states of the world, the $\sigma$-field $\mathcal{F}$ consists of all subsets of $\Omega$, and $\P$ is a probability measure. Let $A \in \mathcal{F}$ denote an event of interest. 
%The set of possible outcomes is denoted with $S$. For the sake of illustration, assume that  $S = \{G, B\}$, where $G$ and $B$ denote good and bad outcomes, respectively. The outcome function $F: \Omega \to S$ is a random variable that maps the state of the world to the true outcome. 
The experts aim to forecast the probability of $A$ occurring $p = \P(A)$. Even though this paper focuses on probability estimates, the following discussion can be easily generalized to different types of estimates. 

Generated estimates can be considered as noisy or distorted versions of $p$. In other words, if $\xi: [0,1] \to [0,1]$ is a noise function that randomly distorts a probability, then a generated probability forecasts is realized by $p_i = \xi(p)$. Due to its mathematical convenience, this framework is typically applied to subjective response data. Unfortunately, it can be drastically misaligned with the psychology literature and hence lead to results that are not reflective of the actual process that generates the estimates.

%Therefore any heterogeneity in the estimates stems from randomness that is typically assumed to be caused by uncontrolled or unmeasured factors. 
%Even though this framework is mathematically convenient, it can be drastically misaligned with the psychology literature and hence lead to results that are not reflective of the actual environment that produces the estimates.
%The interoperation framework aims to correct these shortcomings by proposing a model that is more cognitive based. See \cite{hong2009interpreted} for the original introduction. 
Under the interpretive framework, the set of states $\Omega$ is assume to be finite. The expert partitions $\Omega$ into non-overlapping subsets. This partition, know as the \textit{interpretation}, is denoted with $\Pi^i = \{\pi_1^i, \pi_2^i, \dots, \pi_{n_i}^i\}$, where $\bigcup_{j=1}^{n_i} \pi_j^i = \Omega$ and  $\pi_j^i \cap \pi_k^i = \emptyset$ for $j \neq k$. The expert can only associate a state $\omega \in \Omega$ with a set in his partition. Therefore his information is incomplete as long as not all the sets of his partition are singletons. To make probability forecasts, the expert specifies a map $\phi_i: \Omega \to [0, 1]$ that is measurable with respect to $\Pi^i$. 
%Therefore any differences in estimates stem from cognitive diversity of the experts. 
Unfortunately, \cite{hong2009interpreted} does not specify how the expert constructs the map $\phi_i$. It is also not clear how to the set of states $\Omega$ should be specified in complex real-world applications.  



The information theoretic framework removes these intractable components and provides a model that can be applied in practice. It does not assume detailed knowledge of the expert interpretations nor pose any structure or cardinality restrictions on $\Omega$.  Each expert simply forecasts $p_i = \P\left(A | \mathcal{F}_i\right)$ based on a private information set $\mathcal{F}_i \subseteq \mathcal{F}$. 
%If the set $\Omega$ is finite, the information set $\mathcal{F}_i$ can be considered equivalent to the $\sigma$-field generated by the interpretation $\Pi^i$. 
If two experts $i$ and $j$ share information such that $\mathcal{F}_i \cap \mathcal{F}_j \neq \emptyset$, then the correlation of their forecasts $p_i$ and $p_j$ is positive and proportional to the overlap in their information sets. This means that, similarly to the interpretive framework, any heterogeneity in the estimates stems from cognitive diversity. As the details of the information set $\mathcal{F}_i$ cannot be known in practice, the information known by the $i$th expert is quantified as a fraction of the full information. 
%For instance, expert $i$ may know 15\% of the full information while expert $j$ knows only 8\% of the full information. If in addition we specify that their shared information is, say, 3\% of the full information, we have established an information structure for these  experts. 
This leads to a compromise that is mathematically convenient and psychologically reasonable. 

%This is shown in following sections where the information theoretic framework is applied to probability forecasts and their aggregation. 


\section{Model for Probability Forecasts}
\label{Model}
The information theoretic model for probability forecasts is first illustrated with experts 1 and 2. This is then generalized to $N$ number of experts at the end of the section. Under this model the event $A$ is determined by a pool of white noise. Experts 1 and 2 see respective $\delta_1$ and $\delta_2$ portions of the noise. These portions form their information sets. The overlap in these information sets is a fixed share $\rho$ of what is seen by either expert. To make this more precise, let $(\Omega, \mathcal{F}, \P)$ be a probability space. On this space, define a white noise process that is indexed by the unit interval $S = [0,1]$. A white noise process is a Gaussian process $\{ X_B \}$ indexed by Borel measurable subsets $B$. The unit interval is endowed with the uniform measure $\mu$. This gives the white noise process a covariance structure $\text{cov}(X_B, X_{B'}) = \mu(B \cap B') = |B \cap B'|$, i.e. the length of the intersection. The target event is defined as $A = \{ X_{S} > 0\}$. Let $I_1, I_2 \subseteq S$ be the information sets observed by experts 1 and 2, respectively. Then,
\begin{align*}
\mu(I_1) = |I_1| &= \delta_1\\
\mu(I_2) = |I_2| &= \delta_2\\
\mu(I_1 \cap I_2) =  |I_1 \cap I_2| &= \rho
\end{align*}
Call $X_{I_j}$ the probit forecast of the $j$th expert.  If $\Phi$ denotes the standard normal CDF, then
\begin{align*}
p_j &= \P(A | \mathcal{F}_{I_j}) = \Phi(X_{I_j})
\end{align*}
for $j = 1, 2$. The best in-principle forecast given the knowledge of the two experts is $P(X_{S} > 0 |  \mathcal{F}_1 \cup \mathcal{F}_2)$. This, however, assumes that the experts can pool information optimally with each other. Therefore the best aggregate probability that can be realistically expected is $\P(X_{S} > 0 | p_1, p_2)$.

\begin{figure}[htbp]
%   \hspace{-2em}
   \includegraphics[width = \textwidth]{N=2} % requires the graphicx package
   \caption{Illustration of the information theoretic model with two experts.}
   \label{diagram2}
\end{figure}

Figure \ref{diagram2} illustrates the model with $N=2$. The Gaussian process has been partitioned into four parts based on the information sets $I_1$ and $I_2$:
\begin{align*}
 U &= X_{I_1 / I_2}
& M &= X_{I_1 \cap I_2}\\
 V &= X_{I_2 / I_1}
& W &= X_{(I_1 \cup I_2)^c}
\end{align*}
Then,
\begin{align*}
X_{I_1} &= U + M\\
X_{I_2} &= M + V\\
X_S &= U+M+V+W,
\end{align*}
where $U, V, M, W$ are independent Gaussians with respective variances $\delta_1-\rho$, $\delta_2-\rho$, $\rho$, $1+\rho-\delta_1 - \delta_2$. This gives $(X_{S}, X_{I_1}, X_{I_2})$ a multivariate normal distribution. More specifically,  
\begin{align}
\left(\begin{matrix} X_S \\ X_{I_1}\\ X_{I_2} \end{matrix}\right) &\sim \mathcal{N}\left(
 \boldsymbol{0},  \left(\begin{matrix} 
1 & \delta_1 & \delta_2\\
\delta_1 & \delta_1 &\rho\\
\delta_2 & \rho & \delta_2
 \end{matrix}\right)\right) \label{twoExperts}
\end{align}

\begin{figure}[htbp]
   \includegraphics[width = \textwidth]{N=N} % requires the graphicx package
   \caption{Illustration of the information theoretic  model with $N$ experts.}
   \label{diagramN}
\end{figure}



Consider now $N$ experts. Let $|I_j| = \delta_j$ be the amount of information known by the $j$th expert, and $|I_i \cap I_j| = \rho_{ij}$ be the information overlap between the $i$th and $j$th experts. Then expression (\ref{twoExperts}) readily generalizes to the vector $(X_{S}, X_{I_1}, X_{I_2}, \dots, X_{I_N})$. Then,
\begin{align*}
\left(\begin{matrix} X_S \\ X_{I_1}\\ \vdots \\ X_{I_N} \end{matrix}\right) &\sim \mathcal{N}\left( \left(\begin{matrix} 
\mu_1 \\ \boldsymbol{\mu}_2
 \end{matrix}\right) =
 \boldsymbol{0}, \left(\begin{matrix} 
\Sigma_{11} & \Sigma_{12}\\
\Sigma_{21} & \Sigma_{22}\\
 \end{matrix}\right) 
 =
 \left(\begin{array}{c | c c cc }
1 & \delta_1 & \delta_2 & \dots & \delta_N  \\ \hline
\delta_1 & \delta_1 &\rho_{1,2} & \dots & \rho_{1,N}   \\ 
\delta_2 & \rho_{2,1} & \delta_2 & \dots & \rho_{2,N}  \\ 
\vdots & \vdots & \vdots & \ddots & \vdots  \\ 
\delta_N & \rho_{N,1} & \rho_{N,2} & \dots & \delta_N\\ 
 \end{array}\right)\right)
\end{align*}
This extension illustrated in Figure \ref{diagramN}. It is important to notice that the $I_j$ does not have to be a contiguous segment of the unit interval. The sub-matrix $\Sigma_{22}$ fully describes the information structure among the experts.  This matrix has some technical conditions such as symmetry and non-singularity. In addition, $\Sigma_{22}$ must describe a coherent information structure. The matrix $\Sigma_{22}$ is coherent if and only if its information can be transformed into a diagram such as the one depicted by Figure \ref{diagramN}. It is easy to provide a counter-example which shows that not all covariance matrices of size $N \times N$ give coherent information structures.



%Thus $\bar{X}$ is extremized when
%\begin{align*}
% \frac{N \boldsymbol{1}_{N}' \Sigma_{22}^{-1} \boldsymbol{X}}{\boldsymbol{1}_{N}'  \boldsymbol{X}  \sqrt{N - \boldsymbol{1}_{N}' \Sigma_{22}^{-1} \boldsymbol{1}_{N}}}   &>& 1\\
% \frac{\boldsymbol{1}_{N}' \Sigma_{22}^{-1} \boldsymbol{X}}{\boldsymbol{1}_{N}'  \boldsymbol{X}  }   &>& \sqrt{ \frac{1}{N} - \frac{\boldsymbol{1}_{N}' \Sigma_{22}^{-1} \boldsymbol{1}_{N}}{N^2}},
%\end{align*}
%where the LHS side a weighed average of the elements of $\Sigma_{22}^{-1}$. This becomes clear after noticing that $\boldsymbol{X} / \boldsymbol{1}_{N}'  \boldsymbol{X}$ is a vector whose elements sum to 1. These give the weights for each respective column of $\Sigma_{22}^{-1}$. Hence the larger a given $X_j$ is the more influence it has in his weighted sum. The second term on RHS is the equally weighed average of $\Sigma_{22}^{-1}$. Notice that LHS increases as a function of $\Sigma_{22}^{-1}$ while RHS decreases. In addition, if $\boldsymbol{1}_{N}' \Sigma_{22}^{-1}  \boldsymbol{1}_{N} > \approx 1.1$ and fixed, then RHS decreases as $N$ increases. This largely revolves around understanding the interpretation of the precision matrix. 
%
%\begin{align*}
% \frac{( \boldsymbol{1}_{N}' \Sigma_{22}^{-1} \boldsymbol{X} )( \boldsymbol{X}'  \Sigma_{22}^{-1}\boldsymbol{1}_{N} )}{(\boldsymbol{1}_{N}'  \boldsymbol{X} )(  \boldsymbol{X}'  \boldsymbol{1}_{N})}   &>& \frac{1}{N} - \frac{\boldsymbol{1}_{N}' \Sigma_{22}^{-1} \boldsymbol{1}_{N}}{N^2}\\
%\end{align*}


\section{Extremization}



Let $\boldsymbol{X}$ be a column vector of length $N$ such that $X_j = X_{I_j}$ for $j = 1, \dots, N$. If $\Sigma_{22}$ is a coherent overlap structure and $\Sigma_{22}^{-1}$ exists, then $X_{S} | \boldsymbol{X} \sim \mathcal{N}(\bar{\mu}, \bar{\Sigma})$, where
\begin{align}
\bar{\mu} &= \mu_1 + \Sigma_{12} \Sigma_{22}^{-1} (\boldsymbol{X} - \boldsymbol{\mu}_2) =  \Sigma_{12} \Sigma_{22}^{-1} \boldsymbol{X} \label{condMu}
\end{align}
and
\begin{align}
 \bar{\Sigma}&= \Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21} =1 - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21}  \label{condSigma}
\end{align}
See Result 5.2.10 on p. 156 in \cite{ravishanker2001first} for the formulas of a conditional multivariate normal distribution. The aggregator then becomes 
\begin{align*}
\P\left(A  \bigg| \boldsymbol{X}\right)  = \P\left(X_{S} > 0 \bigg| \boldsymbol{X}\right) &= \Phi\left( \frac{\Sigma_{12} \Sigma_{22}^{-1} \boldsymbol{X}}{\sqrt{1 - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21}}}\right)
%&= \Phi\left( \frac{\boldsymbol{1}_{N}'  \Sigma_{22}^{-1} \Phi^{-1}(\boldsymbol{p})}{\sqrt{1 - \boldsymbol{1}_{N}' \Sigma_{22}^{-1} \boldsymbol{1}_{N}}}\right)
\end{align*}
Let $\alpha$ represents the amount of extremization that is performed for the average probit forecast. If $\bar{X} = \left( \sum_{j=1}^N X_{I_j} \right)/N$ denotes the average probit forecast, then
\begin{align}
\alpha \bar{X}&=  \frac{\Sigma_{12} \Sigma_{22}^{-1} \boldsymbol{X}}{\sqrt{1 - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21}}}  &\Leftrightarrow&& \alpha  = \frac{N \Sigma_{12} \Sigma_{22}^{-1} \boldsymbol{X}}{\left(\boldsymbol{1}_N' \boldsymbol{X} \right) \sqrt{1 - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21}}} \label{alpha}
\end{align}
Even though this expression assumes no structure on $\Sigma_{22}$ and depends on $N +\frac{N(N-1)}{2}$ unknown parameters, it can be used to gain insight on the behavior of the extremizing constant $\alpha$. One useful development is to determine the amount of information in $\boldsymbol{X}$. 

\begin{observation}
\label{infoObservation}
If $\delta_0$ denotes the information in $\boldsymbol{X}$, then 
\begin{align*}
%\frac{N \Sigma_{12} \Sigma_{22}^{-1} \boldsymbol{X}}{\left(\boldsymbol{1}_N' \boldsymbol{X} \right) \sqrt{1 - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21}}} &= \alpha\\
%\frac{\Sigma_{12} \Sigma_{22}^{-1} }{\sqrt{1 - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21}}} &= \alpha\\
%\frac{1 }{\sqrt{1 - \delta_0}} &= \alpha\\
%\frac{1}{\sqrt{1-\delta_0}} &= \frac{\frac{N}{(N-1)\rho +1}}{\sqrt{1- \frac{N\delta}{(N-1)\rho +1} }} \\
\alpha &= \frac{1}{\sqrt{1-\delta_0}} &\Leftrightarrow&& \delta_0 &=1-\alpha^{-2}
\end{align*}
\end{observation}
\begin{proof}
Let $\alpha_N$ denote the extremizing constant for $\boldsymbol{X}$. Consider a single expert whose probit forecast is $\bar{X}$. Denote the size of his information set by $\delta_0$. The extremizing constant for his forecast, as is given by (\ref{alpha}), simplifies to
\begin{align*}
\alpha_1  =  \frac{1}{\sqrt{1-\delta_0}}
\end{align*}
Setting $\alpha_1 = \alpha_N$ gives us the final result.

\end{proof}

Based on Observation \ref{infoObservation} there is a monotonic and positive relationship between $\alpha$ and $\delta_0$. Therefore the more the sample average is extremized the more information its corresponding $\boldsymbol{X}$ contains, and \textit{vice versa}. Observation \ref{infoObservation}  is interesting for two reasons: (a) it allows the researcher to use black-box models from existing literature to determine the extremizing constant and then use it to analyze the amount of information in $\boldsymbol{X}$, and (b) it allows us to easily show that $\alpha \geq 1$ under any information structure.

\begin{observation}
\label{positiveThm}
Under the model described in Section \ref{Model}, the extremizing factor, $\alpha$, is always greater or equal to 1. This means that the average probit forecast is always extremized. 
\end{observation}
\begin{proof} 
By Observation \ref{infoObservation} we have that 
\begin{align*}
\alpha &= \frac{1}{\sqrt{1-\delta_0}} 
\end{align*}
Given that $\delta_0 \in [0,1]$, it follows that $\alpha \in [1, \infty)$. 

%By Observation \ref{infoObservation}, the extremizing constant $\alpha$ is the smallest when the sample $\boldsymbol{X}$ has the least amount of information. This happens when all the experts know the same information, and the amount of this information is very small. Assume without loss of generality that $\delta_j = \delta$. Then $\rho_{i,j} = \delta$ and
%\begin{align*}
% \alpha  &= \frac{N \Sigma_{12} \Sigma_{22}^{-1} \boldsymbol{X}}{\left(\boldsymbol{1}_N' \boldsymbol{X} \right) \sqrt{1 - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21}}} = \frac{1}{\sqrt{1- \delta }} \downarrow 1
%\end{align*}
%as $\delta \downarrow 0$.
%We need to show that 
%\begin{align*}
% \frac{N \Sigma_{12} \Sigma_{22}^{-1} \boldsymbol{X}}{\left(\boldsymbol{1}_N' \boldsymbol{X} \right) \sqrt{1 - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21}}} &\geq 1\\
%\end{align*} 
%As $\Sigma_{22}$ is positive semi-definite,  $\Sigma_{22}^{-1}$ is positive definite. Therefore $\Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21} > 0$ and $ \sqrt{1 - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21}} \in [0,1)$. 
\end{proof}

To continue our analysis of extremization, it is necessary to reduce the number of degrees of freedom by assuming a simpler form for the overlap structure $\Sigma_{22}$. 

\subsection{Compound Symmetric Information Structure}

This section assumes that each expert knows equally much and that the amount of information shared between any two experts is a constant fraction of their knowledge. This is equivalent to choosing the following compound symmetric overlap structure. 
% $\rho \in [\max \{(N-T)/(T(N-1)), 0\},1] = A_\rho$. 
\begin{align*}
\left(\begin{matrix} X_{S} \\ X_{I_1}\\ \vdots \\ X_{I_N} \end{matrix}\right) &\sim \mathcal{N}\left( \left(\begin{matrix} 
\mu_1 \\ \boldsymbol{\mu}_2
 \end{matrix}\right) =
 \boldsymbol{0}, \left(\begin{matrix} 
\Sigma_{11} & \Sigma_{12}\\
\Sigma_{21} & \Sigma_{22}\\
 \end{matrix}\right) 
 =
 \left(\begin{array}{c|cccc}
1 & \delta & \delta & \dots & \delta  \\ \hline
\delta & \delta &\rho\delta & \dots & \rho\delta   \\ 
\delta & \rho\delta & \delta & \dots & \rho\delta  \\ 
\vdots & \vdots & \vdots & \ddots & \vdots  \\ 
\delta & \rho\delta & \rho\delta & \dots & \delta\\ 
 \end{array}\right)\right),
\end{align*}
where $\delta \in [0,1]$ is the fraction known by each expert and $\rho \in \left[  \max \left\{ \frac{N-\delta^{-1}}{N-1}, 0\right\}, 1 \right]$ is the shared proportion of the known knowledge. The lower bound for $\rho$ becomes necessary if $\delta > 1/N$ because then overlap in the information sets is unavoidable. This minimum can be computed by assuming $\delta > 1/N$ and letting the shared information be the same for all $N$ experts. That is, $|I_{i} \cap I_j| = |I| =  \rho \delta$ for all $i \neq j$. The minimum sharing occurs, when $\rho\delta + N(\delta - \delta\rho) = 1$, which gives us the lower bound. The quantity  $\rho\delta + N(\delta - \delta\rho)$ also describes the maximum coverage of the $N$ experts. That is, $\rho\delta + N(\delta - \delta\rho) = \max | I_1 \cup I_2 \cup \dots \cup I_N|$. 

Note that this model constrains the marginal distribution of $p_j = \Phi(X_{I_j})$ to be uniform on $[0,1]$ when $\delta_j = 1$. To see this, recall that if $X_{I_j} \sim \mathcal{N}(0,1)$, then $\Phi(X_{I_j})$ is uniform on $[0,1]$. If this does not hold empirically, it is a sign that the model cannot be correct on the micro-level. If $X_{I_j}$ appears more (respectively less) concentrated about $0.5$, then the model can be adjusted by changing $\delta_{j}$ to a smaller fraction. 


%Assuming no further prior information on overlap structure, the expected amount of information held by the group is WHAT IS THIS?

Notice that $\Sigma_{22}$ can be written as  $\Sigma_{22} = I_N (\delta-\rho\delta) + J_{N \times N} \rho\delta$. Therefore its inverse is $\Sigma_{22}^{-1} = I_N \left(\frac{1}{\delta-\rho\delta} \right) - J_{N \times N} \frac{\rho\delta}{(\delta-\rho\delta)((\delta-\rho\delta) + N \rho\delta)}$ (see the supplementary material for \cite{dobbin2005sample}). Applying this to equations (\ref{condMu}) and (\ref{condSigma}) gives us the conditional mean
%By the conditional multivariate normal results, we have that 
%\begin{align*}
%\bar{\mu} &= \mu_1 + \Sigma_{12} \Sigma_{22}^{-1} (\boldsymbol{X} - \boldsymbol{\mu}_2)\\
% &= \Sigma_{12} \Sigma_{22}^{-1} \boldsymbol{X} \\
% \\
% \bar{\Sigma}&= \Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21}\\
%&=1 - \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21}
%\end{align*}
%
%%(see \url{http://linus.nci.nih.gov/techreport/DobbinSimonAppendix.pdf} for this). 
%Hence the off-diagonals of $\Sigma_{22}^{-1}$ are 
%\begin{align*}
%\frac{\rho\delta}{(\rho\delta-\delta)((N-1)\rho\delta +\delta)}
%\end{align*}
%and the diagonals are
%\begin{align*}
%\frac{(2-N)\rho\delta -\delta}{(\rho\delta-\delta)((N-1)\rho\delta +\delta)}
%\end{align*}
%The conditional mean can be derived as
%\begin{align*}
%\Sigma_{22}^{-1} &= \frac{1}{(\rho\delta-\delta)((N-1)\rho\delta +\delta)}
% \left(\begin{matrix} 
%(2-N)\rho\delta -\delta & \rho\delta & \dots & \rho\delta \\ 
%\rho\delta & (2-N)\rho\delta -\delta & \dots & \rho\delta \\ 
%\vdots & \vdots &  \ddots & \vdots \\ 
%\rho\delta & \rho\delta & \dots & (2-N)\rho\delta -\delta  \\ 
% \end{matrix}\right)\\
% \Sigma_{12} \Sigma_{22}^{-1} &= \frac{\delta}{(\rho\delta-\delta)((N-1)\rho\delta +\delta)} \left( \begin{matrix} \rho\delta -\delta &  \dots & \rho\delta -\delta \end{matrix} \right)\\
% \Sigma_{12} \Sigma_{22}^{-1} \boldsymbol{X} &= \frac{\delta}{(\rho\delta-\delta)((N-1)\rho\delta +\delta)} (\rho\delta -\delta) \sum_{j=1}^N X_j \\
%&= \frac{\delta(\rho\delta -\delta)}{(\rho\delta-\delta)((N-1)\rho\delta +\delta)}  \sum_{j=1}^N X_j \\
%&= \frac{\delta}{(N-1)\rho\delta +\delta}  \sum_{j=1}^N X_j \\
\begin{align*}
\bar{\mu} &= \frac{1}{(N-1)\rho +1}  \sum_{j=1}^N X_j 
\end{align*}
and variance 
\begin{align*}
% \bar{\Sigma} &= 1 -  \Sigma_{12} \Sigma_{22}^{-1}\Sigma_{21} \\
% &= 1  - \frac{\delta^2}{(\rho\delta-\delta)((N-1)\rho\delta +\delta)} N(\rho\delta -\delta)\\
% &= 1  - \frac{\delta^2N}{(N-1)\rho\delta +\delta} \\
 \bar{\Sigma} &= 1  - \frac{\delta N}{(N-1)\rho +1} 
\end{align*}
The aggregation rule then becomes 
\begin{align*}
\P\left(X_S > 0 \bigg| \boldsymbol{X}\right) &=\Phi\left(\frac{\frac{1}{(N-1)\rho +1} \sum_{j=1}^N X_{I_j} }{\sqrt{1- \frac{N\delta}{(N-1)\rho +1} }}  \right)
\end{align*}
From this aggregator we obtain an expression for the amount of extremization under the compound symmetric information structure.
\begin{align}
%\alpha \bar{X}  &=  \frac{\frac{1}{(N-1)\rho +1} \sum_{j=1}^N X_j }{\sqrt{T- \frac{N}{(N-1)\rho +1} }}\\
%\alpha &= \frac{\frac{1}{(N-1)\rho +1} \sum_{j=1}^N X_j }{\bar{X} \sqrt{T- \frac{N}{(N-1)\rho +1} }}\\
\alpha &= \frac{\frac{N}{(N-1)\rho +1}}{\sqrt{1- \frac{N\delta}{(N-1)\rho +1} }} \label{CompoundAlpha}
% &= \frac{\frac{N}{(N-1)\rho +1}}{\sqrt{1-\delta  \left( \frac{N}{(N-1)\rho +1}  \right)}} \\
% &= \frac{\gamma}{\sqrt{1-\delta\gamma}},
% &= \frac{N}{\sqrt{((N-1)\rho +1)^2 (T- \frac{N}{(N-1)\rho +1} )}}\\
% &= \frac{N}{\sqrt{((N-1)\rho +1)^2T- N((N-1)\rho +1) )}}
\end{align}
%where 
%\begin{align*}
%\gamma &= \frac{N}{(N-1)\rho +1}\\
%&= \left( \frac{1}{(N-1)\rho +1} \right) N\\
%\end{align*}
%WHAT IS GAMMA? Given that 
%\begin{align*}
%\gamma \delta &\leq 1\\
%% \frac{N \delta}{(N-1)\rho +1}  &\leq& 1\\
% \frac{N\delta - 1}{N-1}  &\leq \rho,
%\end{align*}
Unlike (\ref{alpha}), the extremizing constant under the compound symmetric information structure does not depend on the forecasts, $\boldsymbol{X}$. As the term inside the square-root must be non-negative, we have another technical restriction on $\rho$. That is, in addition to $\rho \in \left[  \max \left\{ \frac{N-\delta^{-1}}{N-1}, 0\right\}, 1 \right]$, we require
\begin{align*}
\rho \geq \frac{N\delta - 1}{N-1}
\end{align*}
Notice, however, that $N\delta - 1 > N - \delta^{-1}$ only when $\delta < 1/N$. But when $\delta < 1/N$, both $N\delta - 1$ and $N - \delta^{-1}$ are negative. Therefore this technical condition is redundant and can be ignored. 




%As $\frac{N}{(N-1)\rho +1} \in [1, N]$, this quantity can be thought of as the amount of knowledge that the group knows. Therefore $\alpha$ is a ratio of the amount of knowledge known and the amount of knowledge that is unknown to the group. This makes intuitively sense because if the group knows almost all of $T$, then their average should be heavily extremized.
% If the group of experts is large, then $N-1 \approx N$ and 
%\begin{align*}
%\alpha &= \frac{\frac{N}{N\rho +1} }{\sqrt{T- \frac{N}{N\rho +1} }}
%\end{align*}
%
%\begin{verbatim}
%library(lattice)
%N = 10
%#deltas = seq(0.001, 2/N, length = 500)
%deltas = seq(0.001, 0.999, length = 500)
%rhos = seq(0.001, 1, length = 500)
%grid = expand.grid(deltas, rhos)
%#grid =  grid[grid[,2] < grid[,1], ]
%thresh = (N-1/grid[,1])/(N-1)
%grid = grid[thresh <= grid[,2] ,]
%
%alphas = N/((N-1)*grid[,2] + 1) / sqrt(1-N*grid[,1]/((N-1)*grid[,2] + 1))
%grid = cbind(alphas, grid)
%
%
%#col.l = c(colorRampPalette(c('darkblue', 'skyblue'))(9), colorRampPalette(c('darksalmon', 'darkred'))(11))
%
%alphas = log(alphas)
%L = 50
%#col.l =  colorRampPalette(c('coral', 'coral4', 'darkred'))(L)
%col.l = colorRampPalette(c("yellow","red", "darkred", "black"))(L) 
%#ats = seq(1, max(alphas, na.rm = TRUE), length = L)
%#ats = ats[-10]
%ats = seq(min(alphas), max(alphas), length = L)
%
%
%setwd("/Users/ville/extremization_paper/")
%jpeg(paste("ExtremeN", N, ".jpeg", sep= ""), pointsize = 15)
%levelplot(alphas~grid[,2]+grid[,3], ylab = expression(rho), xlab = expression(delta), col.regions = col.l, pretty = TRUE, at = ats, contour = TRUE)
%dev.off()
%\end{verbatim}

%
%
%\begin{figure}[hbt!]
%\begin{minipage}[t]{0.33\textwidth}
%\centering
%\includegraphics[width=\textwidth, height = \textwidth]{ExtremeN2.jpeg}
%\caption{N = 2}
%\label{ExtremeN5}
%\end{minipage}
%\begin{minipage}[t]{0.33\textwidth}
%\centering
%\includegraphics[width=\textwidth, height = \textwidth]{ExtremeN5.jpeg}
%\caption{N = 5}
%\label{ExtremeN10}
%\end{minipage}
%\begin{minipage}[t]{0.33\textwidth}
%\centering
%\includegraphics[width=\textwidth, height = \textwidth]{ExtremeN10.jpeg}
%\caption{N = 10}
%\label{ExtremeN30}
%\end{minipage}
%\end{figure}


\begin{figure}
        \centering
        \begin{subfigure}[b]{0.32\textwidth}
                \includegraphics[width=\textwidth]{ExtremeN2.jpeg}
\caption{N = 2}	
\label{ExtremeN5}
        \end{subfigure}%
        ~ %add desired spacing between images, e. g. ~, \quad, \qquad etc.
          %(or a blank line to force the subfigure onto a new line)
        \begin{subfigure}[b]{0.32\textwidth}
                \includegraphics[width=\textwidth]{ExtremeN5.jpeg}
\caption{N = 5}
\label{ExtremeN10}
        \end{subfigure}
        ~ %add desired spacing between images, e. g. ~, \quad, \qquad etc.
          %(or a blank line to force the subfigure onto a new line)
        \begin{subfigure}[b]{0.32\textwidth}
                \includegraphics[width=\textwidth]{ExtremeN10.jpeg}
\caption{N = 10}
\label{ExtremeN30}
        \end{subfigure}
        \caption{ The amount of log-extremization, $\log(\alpha)$ under different combinations of $N$ (the number of experts), $\delta$ (the amount of information known by one expert), and $\rho$ (the amount of information shared by any two experts)}
\end{figure}



Expression (\ref{CompoundAlpha}) is particularly convenient because it only depends on three intuitive parameters. Therefore it can be analyzed graphically. Figures \ref{ExtremeN5} to \ref{ExtremeN30} describe the amount of log-extremization, $\log(\alpha)$, under different values of $\rho, \delta$, and $N$. By Theorem \ref{positiveThm} the amount of extremizing is always greater or equal to 1.0. Notice that most extremization occurs when $\delta = 1.0$ and $\rho = 1$, or when  $\delta = 1/N$ and $\rho = 0$. In the first case, all $N$ experts know whether the event $A$ materializes or not. In the second case, each expert holds an independent set of information such that the group knows all the information. Such a group of experts can re-construct $X_S$ by simply adding up their individual probit forecasts. This means that aggregation becomes voting: if the sum of the probit forecasts is above 0, the event $A$ materializes; else it does not. A similar observation has been made under the interpreted framework (see the example on information aggregation in \cite{hong2009interpreted}). Therefore in the real-world, voting can be expected to work well when the voters form a very knowledgable and diverse group of people. 


 As we move from these two extreme points towards the upper left corner, where $\delta = 0.0$ and $\rho = 1.0$, the amount of extremizing decreases monotonically to $1.0$. This trend can be deduced directly from Observation \ref{infoObservation}. The decrease in the amount of information in $\boldsymbol{X}$  is caused by a combination of (i) decrease in the amount of information that each individual expert holds and (ii) increase in the amount of shared information. Therefore the more knowledgable and diverse the group of experts is, the more their average probit forecast should be extremized. Contrast this with the generated framework where higher variance is typically considered negative. Under the information theoretic and interpreted frameworks, however, higher variance implies broader diversity among the experts and hence is considered helpful. 

From Figures \ref{ExtremeN5} to \ref{ExtremeN30} it is clear that the feasible set of $(\delta, \rho)$-values becomes smaller as $N$ increases. This limitation arises from assuming a compound symmetric overlap structure. Having many experts, each with a considerable amount of information, simply leads to unavoidable overlap in the information sets. From the domain restriction on $\rho$, it is clear that $\rho \to 1$ as $N \to \infty$. Therefore in the limit the group of experts is equivalent to a single expert. This is clearly an unrealistic result. When $N = 2$, on other hand, the compound symmetric overlap is completely general. Therefore assuming a compound symmetric information structure can be appropriate for small numbers of experts but becomes overly restrictive as more experts enter the group. 

%\subsection{Information in the Sample Average}
%It is possible to determine the amount of information in the sample average. This is done by first computing the aggregate probability for the sample average, and then finding the amount of information that a single expert should have in order for his aggregate probability to match with the aggregate probability of the sample average. That is, if $\delta_0$ denotes the information in the sample average, then 
%\begin{align*}
%%\frac{1}{\sqrt{1-\delta_0}} &= \frac{\frac{N}{(N-1)\rho +1}}{\sqrt{1- \frac{N\delta}{(N-1)\rho +1} }} \\
%\alpha &= \frac{1}{\sqrt{1-\delta_0}} &\Leftrightarrow&& \delta_0 &=1-\alpha^{-2}
%\end{align*}
%Based on these equation we notice that there is a monotonic and positive relationship between $\alpha$ and $\delta_0$. This means that the more the sample average is extremized the more information it contains, and \textit{vice versa}. This result is interesting because it allows the researcher to first use black-box models from earlier literature to determine the amount of extremization and then use this quantity to analyze the portion of information that is present in the sample average. 

%
%
%\subsection{Integrate over the prior distribution}
%
%In this section we assumed that we know how much each expert knows but have no idea how much each information each experts shares. Denote $M = \max \left\{ \frac{N\delta-1}{N-1}, 0\right\}$ and assume a uniform prior on $\rho \in [M, \delta]$. That is, let $p(\rho) = (\delta - M)^{-1}$. Then,
%\begin{align*}
%\E_\rho[\alpha] &= \E \left[\frac{\frac{\delta N}{(N-1)\rho +\delta}}{\sqrt{1- \frac{N\delta^2}{(N-1)\rho +\delta} }} \right]\\
%&= (\delta - M)^{-1}  \int_{M}^\delta \frac{\frac{\delta N}{(N-1)\rho +\delta}}{\sqrt{1- \frac{N\delta^2}{(N-1)\rho +\delta} }}   d\rho\\
%\end{align*}
%Let $z = (N-1)\rho +\delta$. Then $dz = (N-1)d\rho \Rightarrow (N-1)^{-1}dz = d\rho$   and 
%\begin{align*}
%&= \frac{1}{(N-1)(\delta - M)}  \int_{(N-1)M+\delta}^{N\delta} \frac{\frac{\delta N}{z} }{\sqrt{1- \frac{N\delta^2}{z} }}  dz\\
%&= \frac{N\delta}{(N-1)(\delta - M)} \int_{(N-1)M+\delta}^{N\delta} \frac{1}{\sqrt{z^2- N\delta^2 z }}  dz\\
%&= \frac{N\delta}{(N-1)(\delta - M)} \int_{(N-1)M+\delta}^{N\delta} \frac{1}{\sqrt{z^2- 2 \frac{N\delta^2}{2} z + \left( \frac{N\delta^2}{2} \right)^2 - \left( \frac{N\delta^2}{2} \right)^2}}  dz\\
%&= \frac{N\delta}{(N-1)(\delta - M)} \int_{(N-1)M+\delta}^{N\delta} \frac{1}{\sqrt{\left( z- \frac{N\delta^2}{2} \right)^2 - \left( \frac{N\delta^2}{2} \right)^2}}  dz
%\end{align*}
%Let $u =  z- \frac{N\delta^2}{2}$. Then $du = dz$ and 
%\begin{align*}
%&=\frac{N\delta}{(N-1)(\delta - M)} \int_{(N-1)M+\delta- \frac{N\delta^2}{2}}^{N\delta- \frac{N\delta^2}{2}} \frac{1}{\sqrt{u^2 - \left( \frac{N\delta^2}{2} \right)^2}}  du\\
%&= \frac{N\delta}{(N-1)(\delta - M)} \left\{\log \left(\sqrt{4u^2 - \delta^4N^2} + 2u \right) \right\}\bigg|_{(N-1)M+\delta- \frac{N\delta^2}{2}}^{N\delta- \frac{N\delta^2}{2}}\\
%&= \frac{N\delta}{(N-1)(\delta - M)} \left\{\log \frac{ \sqrt{4\left( N\delta- \frac{N\delta^2}{2} \right)^2 - \delta^4N^2} + 2\left(N\delta- \frac{N\delta^2}{2} \right)}{\sqrt{4\left( (N-1)M+\delta- \frac{N\delta^2}{2} \right)^2 - \delta^4N^2} + 2\left( (N-1)M+\delta- \frac{N\delta^2}{2} \right) } \right\}\\
%%&= \frac{N\delta}{(N-1)(\delta - M)} \left\{\log \frac{N \sqrt{4\delta^2 \left(1- \frac{\delta}{2} \right)^2 - \delta^4} + 2\left(N\delta- \frac{N\delta^2}{2} \right)}{\sqrt{4\left( (N-1)M+\delta- \frac{N\delta^2}{2} \right)^2 - \delta^4N^2} + 2\left( (N-1)M+\delta- \frac{N\delta^2}{2} \right) } \right\}\\
%\end{align*}
%This can be plotted on a grid of values of $\delta$ and $N$. 
%\begin{center}
%   \includegraphics{rhoIntegratedPrior.jpeg} % requires the graphicx package
%\end{center}
%Moving from the middle to the right, the extremizing stengtens as the experts know more. The less intuitive result is close to the bottom-left corner of the plot. Moving diagonally from the origin, the amount of extremizing increases until the point hits the line $\delta = 1/N$. We must keep in mind that the extermination is always relative to the given mean. If there are many experts that know, say, 0.20, then their mean is (under non-informative prior on $\rho$) much more informative than the mean of only a few experts who know the same amount. Therefore you should extremize the smaller group more. 
%
%
%If $M = 0 \Leftrightarrow \delta \leq 1/N$ , this equals to 
%\begin{align*}
%&= \frac{ N \log \left( (2-\delta+2\sqrt{1-\delta})\delta N\right)}{(N-1)} -
%\frac{N \log (\delta (2 - \delta N + 2 \sqrt{1-\delta N}))}{N-1} \\
%&= \frac{N}{N-1} \left(\log \left( (2-\delta+2\sqrt{1-\delta})\delta N\right)- \log (\delta (2 - \delta N + 2 \sqrt{1-\delta N})) \right) \\
%&= \frac{N}{N-1} \left(\log \frac{2N-\delta N+2\sqrt{1-\delta}N) }{2 - \delta N + 2 \sqrt{1-\delta N}} \right) \\
%\end{align*}
%If, on other hand, $M = \frac{N \delta -1}{N-1}$, then
%
%
%%
%%\begin{verbatim}
%%delta = 0.1
%%N = 100
%%M = max((N*delta-1)/(N-1), 0)
%%integrand <- function(x) (delta-M)^(-1)*(delta*N/ ((N-1)*x+delta)) / sqrt(1 - (delta^2*N/ ((N-1)*x+delta)))  
%%integrate(integrand, lower = M, upper = delta)
%%
%%integrand <- function(x)   (N*delta/((N-1)*(delta-M))) * 1/sqrt((x-N*delta^2/2)^2 -(N*delta^2/2)^2)
%%integrate(integrand, lower = (N-1)*M+delta, upper = N*delta)
%%
%%integrand <- function(x)   (N*delta/((N-1)*(delta-M))) * 1/sqrt(x^2 -(N*delta^2/2)^2)
%%integrate(integrand, lower = (N-1)*M+delta - N*delta^2/2, upper = N*delta-N*delta^2/2)
%%
%%
%%f = function(u, delta, N) log(sqrt(4*u^2 - delta^4*N^2)+2*u)
%%
%%get.alpha = function(delta,N){
%%	M = max((N*delta-1)/(N-1), 0)
%%	up = N*delta - N*delta^2/2
%%	low = (N-1)*M + delta - N*delta^2/2
%%	 N*delta/((N-1)*(delta-M)) *(f(up, delta, N) - f(low, delta, N))
%%}
%%
%%deltas = seq(0.01, 0.99, 0.001)
%%Ns = 2:100
%%grid = expand.grid(deltas, Ns)
%%alphas = NULL
%%
%%integrand <- function(x) (delta-M)^(-1)*(delta*N/ ((N-1)*x+delta)) / sqrt(1 - (delta^2*N/ ((N-1)*x+delta)))  
%%
%%for(i in 1:nrow(grid)){
%%	#	alphas[i] = get.alpha(grid[i,1], grid[i,2])
%%	N = grid[i,2]
%%	delta = grid[i,1]
%%	M = max((N*delta-1)/(N-1), 0)
%%	alphas[i] = integrate(integrand, lower = M, upper = delta)$value
%%}
%%
%%library(lattice)
%%col.l = c(colorRampPalette(c('skyblue', 'darkblue'))(9), colorRampPalette(c('darksalmon', 'darkred'))(11))
%%ats = c(seq(0, 1, length = 10), seq(1, max(alphas, na.rm = TRUE), length = 11))
%%ats = ats[-10]
%%levelplot(alphas~grid[,1]+grid[,2], ylab = "N (number of experts)", xlab = "delta  (amount known by one expert)", col.regions = col.l, at = ats, pretty = TRUE)
%%
%%
%%plot(alphas[grid[,2] == 10]~deltas, type = "l")
%%abline(v = 1/10)
%%
%%\end{verbatim}
%
%\subsection{Integrate over the posterior distribution}
%In this section, we investigate the amount of extremizing after integrating out $\rho$ with respect to its posterior distribution. 


%\subsection{Prior information}
%
%\section{Inverse Problem}


\section{Conclusion}
This paper introduced a novel framework for the generation of subjective response data. Under this framework any response heterogeneity is assumed to arise from cognitive diversity. The final framework is mathematically tractable. This was illustrated by deriving an information theoretic aggregation rule for multiple probability forecasts. The aggregator was used to derive a closed-form expression for the amount of extremization that should be performed for the average probit forecast. By assuming a simplified information structure, the amount of extremization was studied graphically. This led to many insights on extremization. Given that these insights tend to align with common sense, the framework appears to be appropriate for probability aggregation.

Part of our future work is to continue developing the aggregator under the information theoretic framework. The first step is to place flexible priors on the unknown parameters, $\rho$ and $\delta$, and marginalize these parameters with respect to their posterior distributions. This would lead to a principled aggregator that does not require a separate training set. Instead, it could be applied directly to the data and would replace unprincipled methods such as the mean or median. Another future direction is to derive an information theoretic aggregator for subjective distributions. This is an important problem in Bayesian statistics where analysis heavily depends on the choice of the prior distribution. Often the prior distribution is picked subjectively by the scientist who has previous experience on the problem at hand. If, however, the experiment is conducted by a group of scientists, their prior distributions must aggregated before the statistical analyses can be carried out. 
 
The information theoretic framework is clearly a simplification of the reality. For instance, assuming that each expert produces an optimal probability forecast given his information set may not be a realistic assumption. The experts may believe in false information, hide their true beliefs, or be biased for many other reasons. This could be incorporated in the model by introducing an error term, possibly with a mean of zero, that is applied to the experts probit forecast. The resulting model, which is a hybrid of the generative and information theoretic frameworks, could lead to more realistic results. This improvement, however, may require a sacrifice in mathematical convenience. 


%\bibliographystyle{plain}
\bibliographystyle{plainnat}
\bibliography{biblio}		% expects file "myrefs.bib"



\end{document}